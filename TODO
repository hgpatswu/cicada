Do we allow state-less features applied during composition???
	We need composition-based features for phrase-based MT
	to compute distortion/lexicalized reordering etc. not represented in
	hypergraph struct

	State-less features are sometimes related to composition algorithm,
	such as shift-reduce etc.

Support tree-to-tree transduction:
	We need different ids for target side's lhs. Do we preserve in rule-struct?
	What is the format for tree-fragment? use lisp-like struct?

Better MIRA training

System combination as statitical generation
  Parse nbests
  Collect rules
  Generate from rules

  Problems:
    Use Earley parsing as generation?
    Do we really handle unary rules with cycles/loops?
    Infinite generation: we will clip by the max-length in hypergraph

rename cicada_unite_{hypergraph,lattice,sentence} to cicada_tool_{hypergraph,lattice,sentence}???
